services:
  # Redis - Message broker for Celery
  redis:
    image: redis:7-alpine
    container_name: smartcache-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Django Backend (with Channels for WebSocket)
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: smartcache-backend
    ports:
      - "8000:8000"
    environment:
      - DEBUG=True
      - SECRET_KEY=${SECRET_KEY:-dev-secret-key-change-in-production}
      - DATABASE_URL=sqlite:////app/db.sqlite3
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - ALLOWED_HOSTS=localhost,127.0.0.1,backend
      - CORS_ALLOWED_ORIGINS=http://localhost:5173,http://localhost:3000,http://frontend:5173
      # AWS S3 credentials (set in .env file)
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_S3_BUCKET_NAME=${AWS_S3_BUCKET_NAME:-}
      - AWS_S3_REGION=${AWS_S3_REGION:-us-east-1}
      # NewsAPI key for news sources
      - NEWSAPI_KEY=${NEWSAPI_KEY:-}
      # Ollama for AI agents
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1}
    volumes:
      - .:/app
      - static_volume:/app/staticfiles
      - media_volume:/app/media
    depends_on:
      redis:
        condition: service_healthy
    command: >
      sh -c "python manage.py migrate &&
             python manage.py collectstatic --noinput &&
             daphne -b 0.0.0.0 -p 8000 smartcache.asgi:application"
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Celery Worker - Background task processing
  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: smartcache-celery-worker
    environment:
      - DEBUG=True
      - SECRET_KEY=${SECRET_KEY:-dev-secret-key-change-in-production}
      - DATABASE_URL=sqlite:////app/db.sqlite3
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_S3_BUCKET_NAME=${AWS_S3_BUCKET_NAME:-}
      - AWS_S3_REGION=${AWS_S3_REGION:-us-east-1}
      - NEWSAPI_KEY=${NEWSAPI_KEY:-}
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1}
    volumes:
      - .:/app
      - media_volume:/app/media
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_started
    command: celery -A smartcache worker --loglevel=info --concurrency=2
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Celery Beat - Scheduled task scheduler (OPTIONAL - disable for manual control)
  # Uncomment if you want automatic hourly ETL runs
  # celery-beat:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   container_name: smartcache-celery-beat
  #   environment:
  #     - DEBUG=True
  #     - SECRET_KEY=${SECRET_KEY:-dev-secret-key-change-in-production}
  #     - DATABASE_URL=sqlite:////app/db.sqlite3
  #     - REDIS_URL=redis://redis:6379/0
  #     - CELERY_BROKER_URL=redis://redis:6379/0
  #     - CELERY_RESULT_BACKEND=redis://redis:6379/0
  #   volumes:
  #     - .:/app
  #   depends_on:
  #     redis:
  #       condition: service_healthy
  #     backend:
  #       condition: service_started
  #   command: celery -A smartcache beat --loglevel=info

  # React Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: smartcache-frontend
    ports:
      - "5173:80"
    environment:
      - VITE_API_URL=http://localhost:8000
      - VITE_WS_URL=ws://localhost:8000
    depends_on:
      - backend

volumes:
  redis_data:
  static_volume:
  media_volume:

